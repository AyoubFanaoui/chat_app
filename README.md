# ğŸ’¬ Chat IA avec Ollama, Flutter et Flask

Ce projet est une application simple de messagerie entre un utilisateur et un modÃ¨le IA local (comme `llama3`, `phi3`, etc.) grÃ¢ce Ã  [Ollama](https://ollama.com), avec une interface moderne Flutter et un backend Flask.

## ğŸš€ Technologies utilisÃ©es

- ğŸ§  [Ollama](https://ollama.com) â€” serveur local de modÃ¨les LLM
- ğŸ Flask â€” backend Python
- ğŸ’™ Flutter â€” frontend mobile/web
- ğŸŒ API REST â€” communication via HTTP

##  AperÃ§u

![alt text](image.png) <!-- ajoute une image du chat si tu veux -->

## ğŸ“¦ Installation

### 1. Lancer Ollama
ollama serve
ollama run tinyllama  # ou phi3, tinyllama...
